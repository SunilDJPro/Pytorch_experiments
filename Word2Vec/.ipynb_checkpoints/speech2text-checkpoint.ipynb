{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMfloB+V2xg4IH64dJ+/pGa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"txvy0tzs3rjy"},"outputs":[],"source":["import torch\n","import torchaudio\n","from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n","\n","# Load pre-trained Wav2Vec2.0 model and tokenizer from Hugging Face\n","tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n","model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n","\n","# Load and preprocess the audio file\n","def load_audio(file_path):\n","    waveform, sample_rate = torchaudio.load(file_path)\n","    return waveform, sample_rate\n","\n","# Preprocess the waveform\n","def preprocess_audio(waveform, sample_rate):\n","    # If sample rate is not 16kHz, resample it\n","    if sample_rate != 16000:\n","        transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n","        waveform = transform(waveform)\n","    return waveform\n","\n","# Convert audio to text using the Wav2Vec2.0 model\n","def speech_to_text(wav_file):\n","    waveform, sample_rate = load_audio(wav_file)\n","    waveform = preprocess_audio(waveform, sample_rate)\n","\n","    # Tokenize and feed to model\n","    inputs = tokenizer(waveform.squeeze().numpy(), return_tensors=\"pt\", padding=True)\n","    with torch.no_grad():\n","        logits = model(inputs.input_values).logits\n","\n","    # Decode the output logits into text\n","    predicted_ids = torch.argmax(logits, dim=-1)\n","    transcription = tokenizer.decode(predicted_ids[0])\n","\n","    return transcription\n","\n","# Provide the path to your WAV file\n","wav_file = 'your_audio_file.wav'\n","transcription = speech_to_text(wav_file)\n","print(f\"Transcription: {transcription}\")"]}]}